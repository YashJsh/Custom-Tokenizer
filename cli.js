#!/usr/bin/env node

import readline from 'readline';
import Tokenizer from './custom_embedding.js';

class TokenizerCLI {
    constructor() {
        this.tokenizer = new Tokenizer();
        this.rl = readline.createInterface({
            input: process.stdin,
            output: process.stdout
        });
    }

    encodeCommand(args) {
        if (args.length === 0) {
            console.error('โ Error: Please provide text to encode');
            console.log('๐ก Usage: encode "Your text here"');
            return;
        }
        
        const text = args.join(' ');
        console.log(`\n๐ค Encoding text: "${text}"`);
        console.log('='.repeat(50));
        
        try {
            const result = this.tokenizer.encode(text);
            console.log('\nโ ENCODING RESULTS');
            console.log('๐ Original text:', result.originalText);
            console.log('๐งน Cleaned text:', result.cleanedText);
            console.log('๐ Words:', result.words);
            console.log('๐ข Token IDs:', result.tokenIds);
            console.log('๐ Token count:', result.tokenCount);
            console.log('๐ Vocabulary size:', result.vocabularySize);
        } catch (error) {
            console.error('โ Error during encoding:', error.message);
        }
    }

    decodeCommand(args) {
        if (args.length === 0) {
            console.error('โ Error: Please provide token IDs to decode');
            console.log('๐ก Usage: decode "[0,1,2,3]" or decode 0,1,2,3');
            return;
        }

        let tokenIds;
        try {
            const input = args.join(' ');
            if (input.startsWith('[') && input.endsWith(']')) {
                tokenIds = JSON.parse(input);
            } else {
                tokenIds = input.split(',').map(id => parseInt(id.trim()));
            }
        } catch (error) {
            console.error('โ Error: Invalid token ID format. Use "[0,1,2,3]" or "0,1,2,3"');
            return;
        }

        console.log(`\n๐ Decoding token IDs: [${tokenIds.join(', ')}]`);
        console.log('='.repeat(50));

        try {
            const result = this.tokenizer.decode(tokenIds);
            console.log('\nโ DECODING RESULTS');
            console.log('๐ Decoded text:', result);
        } catch (error) {
            console.error('โ Error during decoding:', error.message);
        }
    }

    showVocabCommand() {
        this.tokenizer.showVocabulary();
    }

    clearVocabCommand() {
        this.tokenizer.clearVocab();
    }

    helpCommand() {
        console.log(`
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ            ๐ค TOKENIZER CLI TOOL             โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

๐ AVAILABLE COMMANDS:
  encode <text>        ๐ค Encode text to token IDs
  decode <token_ids>   ๐ Decode token IDs back to text  
  vocab               ๐ Show current vocabulary
  clear               ๐งน Clear current vocabulary
  help                โ Show this help message
  quit                ๐ช Exit the program

๐ก EXAMPLES:
  > encode "Hello world! How are you?"
  > decode "[0,1,2,3,4]"
  > decode "0,1,2,3,4"  
  > vocab
  > clear
  > quit

๐ NOTES:
  โข Text will be cleaned (lowercase, punctuation removed)
  โข Vocabulary is built automatically during encoding
  โข Use 'clear' to reset and start fresh
  โข Token IDs can be provided as JSON array or comma-separated
        `);
    }

    showWelcome() {
        console.log(`
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
โ     ๐ Welcome to Tokenizer CLI Tool!       โ
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

Type 'help' to see available commands or 'quit' to exit.
        `);
    }

    processCommand(input) {
        const trimmed = input.trim();
        if (!trimmed) return;

        const parts = trimmed.split(' ');
        const command = parts[0].toLowerCase();
        const args = parts.slice(1);

        switch (command) {
            case 'encode':
                this.encodeCommand(args);
                break;
            case 'decode':
                this.decodeCommand(args);
                break;
            case 'vocab':
                this.showVocabCommand();
                break;
            case 'clear':
                this.clearVocabCommand();
                break;
            case 'help':
                this.helpCommand();
                break;
            case 'quit':
            case 'exit':
                console.log('\n๐ Thanks for using Tokenizer CLI! Goodbye!');
                this.rl.close();
                return;
            default:
                console.error(`โ Unknown command: "${command}"`);
                console.log('๐ก Type "help" to see available commands');
        }
    }

    start() {
        this.showWelcome();
        
        const prompt = () => {
            this.rl.question('๐ค tokenizer> ', (input) => {
                this.processCommand(input);
                if (!this.rl.closed) {
                    console.log(); // Add spacing
                    prompt();
                }
            });
        };
        
        prompt();
    }
}

const func = ()=>{
    const cli = new TokenizerCLI();
    cli.start();
}

func();